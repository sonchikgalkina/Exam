Билет №38:
1.  Класс ArrayList, LinkedList. Основные реализации. Как работают вставка, удаление, поиск элемента на примере реализаций.
2.  Apache Kafka. Архитектура и основные компоненты. Как работает Producer и его основные конфигурации. Как работает Consumer и его основные конфигурации. Apache Zookeeper – для чего нужен и как устроен. Как работает брокер сообщений. Как устроен Message в Kafka. За счет чего Apache Kafka поддерживает надежность, высокую доступность и высокую производительность. Процесс отправки сообщения в Kafka. Процесс чтения сообщения из Kafka. Процесс удаления сообщения из Kafka. Как в Java работать с Kafka.
3.  Реализовать endpoint в TaskController, которому при запросе передаётся boostrapServers и название топика. В endpoint создаётся consumer Kafka, который читает топик, начиная с самых старых сообщений. Далее в Redis находим строку, по ключу первого сообщения из Kafka ("test") и возвращаем в endpoint значение из Redis, но без каждого второго символа

1.  Класс ArrayList, LinkedList. Основные реализации. Как работают вставка, удаление, поиск элемента на примере реализаций.
ArrayList в Java — это динамический массив, который хранит свои элементы внутри обычного массива объектов (Object[]). Реализует интерфейс List с изменяемым размером массива. Каждый экземпляр ArrayList имеет емкость (CAPACITY). Емкость – это размер массива, который используется для хранения элементов. По мере добавления элементов в ArrayList его емкость автоматически увеличивается. Когда массив заполняется, его ёмкость увеличивается. Новая ёмкость вычисляется по формуле: старая ёмкость * 1.5 + 1. Например, если начальная ёмкость была 10, то после расширения она станет 16.
При увеличении ёмкости создаётся новый массив, и все элементы из старого копируются в новый, что является затратной операцией. Поэтому, если заранее известно, что список будет большим, лучше сразу задать достаточную начальную ёмкость. Удаление элементов из середины списка может быть затратной операцией, так как все последующие элементы смещаются влево, что требует копирования данных. Также стоит отметить, что размер внутреннего массива автоматически не уменьшается после удаления элементов. ArrayList не синхронизирован, поэтому не является потокобезопасным. Если несколько потоков одновременно изменяют список, его состояние может стать непредсказуемым. Если требуется потокобезопасная структура данных, лучше использовать Vector или вручную синхронизировать доступ к ArrayList через блоки синхронизации.

Пример реализации

ArrayList<String> fruits = new ArrayList<>();

fruits.add("Apple");
fruits.add("Banana");
fruits.add(1, "Mango");

String first = fruits.get(0);
int mangoIndex = fruits.indexOf("Mango");

fruits.remove("Banana");
fruits.remove(0);

System.out.println(fruits);

LinkedList реализует интерфейсы List и Deque, предоставляя двусвязный список. Каждый элемент списка (узел) содержит ссылки как на следующий, так и на предыдущий элементы, что делает эту структуру данных двусторонне связанной.

Класс LinkedList содержит три основных поля:

Node<E> first – Ссылка на первый элемент списка.
Node<E> last – Ссылка на последний элемент списка.
int size – Количество элементов в списке

Каждый узел (Node) хранит два элемента: данные и ссылки на следующий и предыдущий узлы.

Добавление элементов в конец списка:

Создаётся новый узел (Node).
Устанавливается значение (item) для нового узла.
Ссылки узла добавляются в конец списка.
Устанавливаются ссылки на предыдущий и следующий узлы (для нового и соседних узлов).

Добавление элемента в середину списка:

Проверяется индекс. Если он отрицательный или превышает размер списка, выбрасывается исключение IndexOutOfBoundsException.
Если индекс равен размеру списка, элемент добавляется в конец.
Вставка в середину происходит перед элементом с указанным индексом:
Метод node(index) находит узел по индексу.
Определяется место вставки (поиск узла идёт с начала или конца списка в зависимости от индекса).
Создаётся новый узел, и его ссылки устанавливаются между соседними узлами.
Обновляются ссылки на предыдущие и следующие узлы для нового элемента и его соседей.
Увеличивается размер списка.

Удаление элемента из связного списка по значению:

Последовательно сравниваются элементы списка с заданным значением, начиная с первого узла.
Когда найден узел с соответствующим значением, элемент сохраняется в отдельную переменную.
Ссылки соседних узлов перенаправляются так, чтобы исключить удаляемый элемент.
Очищаются ссылки и данные узла, который содержал удалённый элемент, и уменьшается размер списка.

Пример реализации

LinkedList<String> books = new LinkedList<>();

books.add("Java");
books.addFirst("C++");
books.addLast("Python");
books.add(1, "Go");

String first = books.getFirst();
String last = books.getLast();
int javaIndex = books.indexOf("Java");

books.removeFirst();
books.removeLast();
books.remove(1);

System.out.println(books);

Как и ArrayList, LinkedList не синхронизирован, что делает его непригодным для использования в многопоточной среде без дополнительной синхронизации.

2.  Apache Kafka. Архитектура и основные компоненты. Как работает Producer и его основные конфигурации. Как работает Consumer и его основные конфигурации. Apache Zookeeper – для чего нужен и как устроен. Как работает брокер сообщений. Как устроен Message в Kafka. За счет чего Apache Kafka поддерживает надежность, высокую доступность и высокую производительность. Процесс отправки сообщения в Kafka. Процесс чтения сообщения из Kafka. Процесс удаления сообщения из Kafka. Как в Java работать с Kafka.

Kafka - брокер сообщений, то есть система, которая реализует концепцию очередей сообщений.
Предоставляемый функционал: прием сообщений, складывание в очередь и предоставление доступа к этим сообщениям.

Кафка состоит из:
Клиентской части:
- отправка сообщений producing
- чтение сообщений consuming
- администрирование данных admin

Серверной части:
В Серверной части существуют такие сущности, как брокеры сообщений - это основная единица обработки данных. Именно брокеры принимают запросы от клиентских частей на отправку, прием сообщений, организацию данных и выполняют все манипуляции с данными, необходимые для работы с кафкой.
Брокеры распределенная часть. Каждый брокер может располагаться на своей отдельной ноде в кластере.
Каждый брокер имеет свой адрес в сети.

Клиентская Api, когда хочет обратиться к серверной части кафки (отправить/принять сообщение) всегда должна обращаться к главной точке.
Главной точкой входа серверной части и в принципе кафки - bootstrap.servers = 192.168.1.1:6667, 192.168.1.2:6667, 192.168.1.3:6667

Обычно Api никто не указывает, так что используют домен test-kafka-cluster:9092.
Каждый брокер это реплика кода кафки, который выполняет обработку запросов от клиентской части.
Также каждый брокер на свой стороне имеет так называемые топики.
Количество топиков, их характеристики задаем мы сами.
Топик - это логическое объединение данных, по их смысловой нагрузке.
Но тут нет ограничения по набору (содержимому) сообщения, то есть мы можем отправлять разные сообщения в один и тот же топик, нет привязки к конкретному формату сообщений для топика. Ограничение есть только логическое, оно на нашем усмотрение.
Топик обычно называется по домену данных, который мы обрабатываем.
Кафка сначала определяет среди брокеров, кто будет лидером конкретного топика, а все остальные будут replica.
Клиентская часть отправляет сообщение, брокер видит запрос и смотрит, что для этого топика лидер брокер 1, он кладет это сообщение сначала в топик 1 брокер 1, а дальше брокер 1 отправляет эти данные в остальные брокеры, между ними происходит синхронизация.
Лидер реплицирует данные в два других брокера. Это делается для надежности.
Кто будет являться репликой, а кто лидером определяет отдельная сущность - Zookeeper.
Сообщение от клиентской части, когда приходит и попадает в серверную часть (кластер кафки), сначала попадает к зукиперу. Зукипер принимает запрос от клиентской части, о том что сообщение отправляется в конкретный топик, но только он знает на каком брокере располагается лидер этого топика и отправляет сообщение в этот топик, а брокер, смотрит у топика реплика фактор и реплицирует это сообщения в другие реплики.
У Zookeeper как и брокеры имеет собственный набор хостов и портов boostrap.servers, но чаще используется zookeeper.quorum =192.168.1.1:2181, 192.168.1.2:2181, 192.168.1.3:2181.
Данные располагаются на брокерах в топиках, но топики в брокерах никак не отмечены. Топики это лишь пометки, где данные должны располагаться, но сами данные это по факту файлики и эти файлики имеют различные теги.
Когда отправляем сообщение в кафку, кафка всегда записывает сообщения на диск, но они записываются на диск, как файлики. Запись на диск тоже обеспечивает дополнительную надежность. В памяти это сообщение не остается, оно может оставаться только если кафка решит его закэшировать.
Сообщения топики распределяют по так называемым партициям. Сообщения в партициях всегда располагаются последовательно. Сообщения в партициях не дублируются. Сообщения дублируются только как реплики на других топиках.
Когда сообщение приходит в брокер, у него два варианта в какую из партиций отправить сообщение:
Высчитываем хэш-код от самого сообщения и по RoundRobin сообщение направляем в конкретную партицию. Таким образом равномерно распределяем сообщения в рамках этого топика.
Если ключ указан, то брокер на основе этого ключа посчитает хэш код, от него возьмет деление по остатку, получится номер партиции и именно в эту партицию всегда будет отправлять все сообщения с данным ключом.
Retention - время жизни сообщений, отслеживается по timestamp.

Клиентская часть
Клиентская часть, которая занимается отправкой сообщений называется — producer, чтением — consumer.
Kafka producer.
Kafka producer, чтобы отправить сообщения должен знать:
bootstrap.servers
Нужны уже готовые данные
Тип сериализатора
Нужно указать топик, куда отправляется сообщение
Кафка producer отправляет сообщения по принципу - отправил и забыл (работает в асинхронном режиме).
В метод send передаем необходимые параметры и отправляем сообщение (не ждем ответа от брокера)
У продюсера две фазы работы:
Отправляет запрос на зукипер или лидирующий брокер на получение метаданных(есть ли такой топик, можно ли работать с таким сериалайзером, существует ли такой бутстрап).
Получив ответ, продюсер отправляет само сообщение.
Выполнив .send это всё запустилось в отдельном потоке и продюсер дальше может заниматься отправкой сообщений, нет никакой блокировки.

Kafka consumer.
Чтобы прочитать сообщения из kafka, нужно указать для KafkaConsumer:
bootstrap.servers
топик
тип десериализатор (ByteArrayDeserializer, StringDeserializer)
Group.id - идентификатор группы для всех консюмеров
Указать откуда читать данные: latest, earliest - то есть начать читать с самых старых сообщений(earliest) в топике или только новые сообщения(latest).

Все консюмеры могут объединяться в Group.id, каждый consumer при чтении цепляется к конкретному топику и конкретным партициям, то есть мы сами не указываем к каким партициям цепляться, мы говорим только топик.
Когда запускаем только один consumer и указываем какие топики с какими партициями читать, то он цепляется к конкретным партициям и начинает вычитывать каждое сообщение по порядку(offset).
Задаем ему group.id = group_consumer_test_1 и параметр auto.offset.reset = earliest(откуда читать сообщение, в данном случае с earliest)
Консюмер прежде чем подключиться к топику, запросит у брокера/зукипера информацию, читал ли кто-то до этого из его группы этот топик, если не читал → он просит разрешение на чтение с earliest. Брокер/зукипер подтверждает и дает информацию про номера партиций и офсеты.
Консюмер работает интервальной вычетке данных(poll интервал), то есть раз в заданное время опрашивает у брокера/зукипера, а есть ли новые сообщения, которые он может прочитать.
Как только сообщение было вычитано и обработано консюмером, он выполняет коммит сообщения, то есть фиксируют на стороне брокера какой номер сообщения (оффсет) уже был успешно прочитан. Это нужно для того, чтобы консюмер эти сообщения не перевычитывал, даже если что-то упало, при повторном запуске ему не придется опять читать эти сообщения c earliest, потому что сохранится информация, что в рамках этой консюмер группы, уже был выполнен комит таких то сообщений, об этом ему сообщит зукипер/брокер при подключении. И соответственно он начнет читать только новые сообщения.
Все комиты сохраняются либо в зукипер, либо в отдельный служебный топик(consumer_offsets)
Один консюмер может читать сразу несколько топиков, для этого у него есть метод subscribe. Но при таком варианте, он может не успевать вычитывать все сообщения, и при приходе retention, можно потерять часть сообщений.
Поэтому в рамках одной группы мы можем запустить несколько консюмеров.









